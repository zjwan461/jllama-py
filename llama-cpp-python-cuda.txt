# linux:
CMAKE_ARGS="-DGGML_CUDA=on" pip install llama-cpp-python

# Windows
$env:CMAKE_ARGS = "-DGGML_CUDA=ON"
$env:CMAKE_GENERATOR = "MinGW Makefiles"
$env:CMAKE_ARGS = "-DGGML_OPENBLAS=on -DCMAKE_C_COMPILER=F:/software/mingw64/bin/gcc.exe -DCMAKE_CXX_COMPILER=F:/software/mingw64/bin/g++.exe"
pip install llama-cpp-python[server]

# 如果之前安装过cpu版本的llama-cpp-python,请先执行 pip uninstall llama-cpp-python -y,pip cache purge 之后重新执行cuda版本安装命令